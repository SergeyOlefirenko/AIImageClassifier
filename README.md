# AI IMAGE CLASSIFIER & ENHANCER
## Description
### Скачиваем dataset из kaggle или других ресурсов
#### https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection (для обучения модели)
#### https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces (на случай необходимости дообучения модели)

### Motivation (описание задачи)
#### Задача включает в себя классификацию изображений с использованием сверточных нейронных сетей (CNN) для распознавания поддельных или отредактированных изображений включая изображения документов, людей, животных, транспортных средств, предметов и т.д.

### Introduction (существующие подходы и релевантные работы)
### Cуществующие подходы
#### В данной задаче бинарной классификации изображений на категории «реальные» и «поддельные» применены методы глубокого обучения, в частности сверточные нейронные сети (CNN).

#### Архитектура CNN представляет собой простую, последовательную модель с использованием сверточных слоев в сочетании с пулинг-слоями и механизмами нормализации, и регуляризации (Dropout, BatchNormalization), что способствует улучшению сходимости и снижению переобучения.

#### Дополнительно применена кастомная стратегия остановки обучения, собственная модификация EarlyStopping. Это позволяет прерывать обучение модели при достижении заданной точности на валидационных данных, что оптимизирует процесс обучения и предотвращает излишнюю подгонку под тренировочный набор.

#### В работе использованы практики построения и обучения нейросетевых моделей для классификации изображений, сочетающие базовые и адаптированные методы, применяемые в машинномом обучении, в частности в компьютерном зрении.

#### Релевантные архитектуры: VGG, ResNet, EfficientNet и другие. Эти архитектуры показывают высокую эффективность в задачах компьютерного зрения, включая детекцию поддельных изображений, обнаружение дипфейков и оценку достоверности визуального контента.

#### Также существуют подходы с использованием аугментации данных и методов transfer learning, позволяющих значительно ускорить обучение и повысить обобщающую способность моделей за счет использования предварительно обученных весов. Одним из современных и производительных подходов является использование моделей EfficientNet, которые обеспечивают высокое качество распознавания при меньшем количестве параметров и меньших вычислительных затратах. Эти модели доступны в библиотеке TensorFlow и могут быть дообучены на пользовательских датасетах с помощью transfer learning. Data Augmentation может включать RandomFlip, RandomRotation, RandomZoom, повышающие обобщающую способность модели.

#### Существующие архитектуры, такие как VGGNet, ResNet и Inception, являются эффективными базовыми моделями, которые часто используются в качестве основы при решении задач классификации изображений, включая детекцию дипфейков и поддельных медиа.

### Релевантные работы включают:

#### "DeepFake Detection using CNN" — архитектура MesoNet, ориентированная на выявление дипфейков. "XceptionNet for deepfake detection" — применение модели Xception, предобученной на ImageNet, к задаче детектирования подделок.

### Применяемые методы:

#### Data Augmentation: RandomFlip, RandomRotation, RandomZoom - повышают обобщающую способность модели. Early Stopping и Custom Callbacks — позволяют прерывать обучение при достижении нужного уровня точности или при отсутствии улучшений, как реализовано в данной работе. Fine-tuning (дообучение) — использование предварительно обученных моделей и их адаптация к конкретной задаче (transfer learning), как показано во второй фазе обучения модели в проекте.

#### Таким образом, данная работа опирается на базовые CNN-принципы и может быть дополнительно улучшена за счет использования более мощных и предобученных архитектур.

### Description (технический подход, который использовали в проекте)
### Технический подход

#### В рамках проекта реализован модуль бинарной классификации изображений на классы «Real» и «Fake» с применением методов глубокого обучения на базе фреймворка TensorFlow/Keras. Вся система включает этапы предварительной обработки данных, построения модели, обучения, валидации, оценки и интеграции пользовательского интерфейса для интерактивного тестирования.

### 1. Подготовка данных

#### Данные были загружены из директории с помощью tf.keras.utils.image_dataset_from_directory.

#### Предобработка изображений: Для обеспечения корректного ввода данных в модель используется ресайзинг и нормализация. Также реализована дополнительная предобработка изображений в оттенках серого и с одним каналом, с учетом возможных различий в каналах изображения (например, ч/б изображения были преобразованы в RGB), что улучшает стабильность модели.

#### Все изображения были приведены к единому размеру 32x32 пикселя и нормализованы (пиксельные значения приведены к диапазону [0, 1]).

#### После этого данные были разделены на три выборки:

#### 70% – обучающая
#### 20% – валидационная 
#### 10% – тестовая

### 2. Архитектура модели

#### Модель реализована с использованием Sequential API и включает следующие компоненты:

#### Три блока сверточных слоев Conv2D с фильтрами 16, 32 и 64 Между блоками используются MaxPooling2D и BatchNormalization для стабилизации обучения Dropout слои (по 25%) добавлены для регуляризации После сверток используется Flatten и два Dense слоя, где финальный слой имеет активацию sigmoid для бинарной классификации

### 3. Обучение модели

#### Модель обучалась с использованием оптимизатора Adam и функции потерь BinaryCrossentropy. Основной метрикой служила accuracy. Для остановки переобучения применялся кастомный callback (CustomEarlyStopping), который завершал обучение, если точность на валидации достигала 93%.

#### Дополнительно реализована визуализация истории обучения (графики Loss и Accuracy), что позволяет анализировать динамику качества модели.

### 4. Оценка качества модели
#### Для количественной оценки качества моделей используются метрики бинарной классификации: Precision, Recall и BinaryAccuracy, что позволяет полноценно оценить производительность и поведение модели на тестовой выборке, сбалансированность модели, а также оценить способность модели различать реальные и поддельные изображения с высокой точностью, особенно в условиях дисбаланса классов.

### 5. Предсказание и интерфейс
#### Модель сохранена в формате .keras и интегрирована в пользовательский интерфейс на базе Tkinter + CustomTkinter, где пользователь может выбрать изображение, визуализировать его и получить предсказание (Real/Fake). Предварительная обработка изображения перед подачей в модель включает изменение размера и нормализацию. Прогнозы классификации выводятся на экран в виде текста: REAL IMAGE или IMAGE MIGHT BE AI-GENERATED OR EDITED.

### 6. Дообучение (Fine-tuning)

#### Обучение с использованием EarlyStopping и дообучение моделей: Применение обратного распространения ошибки и использование критериев остановки (EarlyStopping) для предотвращения переобучения моделей является стандартной практикой при обучении модели.

#### На последнем этапе предусмотрена возможность размораживания слоев модели и дообучения с меньшей скоростью обучения (learning_rate=1e-5, то есть 0.00001) для повышения точности на новых данных, что актуально при переносе обучения (Transfer Learning).

### Denoising и super-resolution

#### В данном проекте реализован подход к улучшению качества изображений с использованием двух ключевых методов: удаление шума (denoising) и увеличение разрешения (super-resolution). Эти методы позволяют повысить качество исходных изображений как перед их классификацией так и для улучшения качества изображений загружаемых пользователем, что реализовано в этом проекте как опция. Подход интегрирован в графический пользовательский интерфейс (GUI) с использованием Tkinter и CustomTkinter для взаимодействия с пользователем.

### 1. Удаление шума (Denoising)

#### Для удаления шума используется функция cv2.fastNlMeansDenoisingColored(), которая применяет алгоритм Нейтральных Средних (Non-Local Means). Этот алгоритм эффективно убирает шум, сохраняя детали и текстуры изображения. Входные параметры задают силу фильтрации, а также настройки для цветных изображений:

#### def denoise_image(image): return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21) None указывает на то, что нет изображения, которое будет использоваться как пример для восстановления.

#### Параметры 10, 10, 7, 21 отвечают за силу денойсинга и параметры поиска соседей.

### 2. Увеличение разрешения (Super-Resolution)

#### Для увеличения разрешения изображения используется функция cv2.resize(), которая выполняет интерполяцию с использованием метода INTER_CUBIC. Это позволяет увеличить размер изображения в два раза с целью улучшения визуального восприятия:

#### def super_resolution(image): # Увеличение изображения sr = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC) return sr Параметры fx=2, fy=2 указывают на увеличение размера изображения в два раза по осям X и Y.

### 3. Порядок применения на изображении

#### Сначала изображение очищается от шума с помощью denoising. Затем оно подвергается увеличению разрешения с помощью super-resolution. Полученные изображения затем визуализируются с помощью Matplotlib, и пользователь может увидеть улучшенную версию изображения.

#### img_denoised = denoise_image(img) img_sr = super_resolution(img_denoised) plt.imshow(img_sr) plt.title('Super-Resolution Image') plt.show()

### Графический интерфейс

#### Для удобства пользователя реализован интерфейс, позволяющий: 
#### Загружать изображение. 
#### Применять методы улучшения качества (удаление шума и увеличение разрешения). 
#### Сохранять результаты в файл. Изменять тему интерфейса между светлой и темной.

### Процесс работы с изображением состоит из следующих этапов:

#### Пользователь загружает изображение. Изображение классифицируется моделью. Применяются улучшения (удаление шума и увеличение разрешения). При необходимости. Результаты обработки отображаются на экране, и пользователь может сохранить изображение.

### Преимущества подхода

#### Удобство интерфейса: Графический интерфейс позволяет пользователю легко взаимодействовать с системой тестируя различные изображения в интерактивном режиме Многофункциональность: Система позволяет не только классифицировать изображения, но и улучшать их качество с помощью методов обработки изображений.

### Заключение

#### В данном проекте реализован подход, который сочетает методы предобработки изображений с нейросетями для классификации на базе фреймворка TensorFlow/Keras, включая расширенные возможности для визуализации, оценки и обработки изображений. Это позволяет повысить точность модели и предоставляет пользователю удобный инструмент для работы с изображениями. Также применение денойсинга и увеличения разрешения, перед обучением модели, может улучшить качество изображений перед классификацией, что может повысить точность модели.

### Demo (демонстрация работы) - App AIImageClassifier.exe
#### Для демонстрации работы приложения достаточно запустить AIImageClassifier.exe и выбрать необходимое изображение для его классификации. Это касается изображений на которых модель не обучалась.

### Results (оценка результатов и эффективности системы, сильные/слабые стороны)
### Оценка результатов и эффективности модели
### Итоговые метрики:
#### Train Accuracy: 93.16% 
#### Validation Accuracy: 93.15% 
#### Precision: 92.55% 
#### Recall: 93.87% 
#### Общая Accuracy: 93.22%

#### Модель демонстрирует достаточно сбалансированные показатели по точности, полноте и общей эффективности.

### Сильные стороны:

#### Высокая обобщающая способность — разница между train и validation accuracy минимальна (0.01%), что говорит об отсутствии переобучения. Хороший баланс между precision и recall: модель одинаково хорошо справляется как с ложноположительными, так и с ложноотрицательными случаями. Успешная остановка обучения (EarlyStopping) на 37-й эпохе — до наступления переобучения, при стабильном снижении val_loss.

### Слабые стороны:

#### Флуктуации в валидационной потере наблюдались на ранних эпохах (8–20), но были стабилизированы к моменту остановки. Модель может быть чувствительна к изменению порога классификации — желательно провести калибровку (например, по ROC-кривой). Сильная зависимость от порога (0.61) — бинарная классификация может выигрывать от калибровки порога (например, через ROC-кривую).

#### Пороговое значение можно откалибровать по ROC или PR-кривой для повышения чувствительности в зависимости от приоритетов задачи. Возможно добавить калибровку порога (например, через sklearn.metrics.roc_curve и precision_recall_curve) так можно получить лучший баланс между Recall и Precision. Для повышения Recall, возможно, слегка дисбалансировать потери или увеличить веса фейкового класса. Протестировать модель на финальном независимом датасете, не участвовавшем в обучении/валидации, чтобы подтвердить обобщающую способность.

#### Переобучения не наблюдается

### Conclusions (будущая работа и возможные улучшения)

#### В будущем, что наиболее вероятно, будет использоваться одна из существующих моделей, например: EfficientNetB3 или ResNet50, а затем, при необходимости Vision Transformer (ViT) или SwinTransformer. Возможно будут использованы другие модели такие как: EfficientNet В0-B7, ResNet101, ConvNeXt и т.д.

#### Будущее развитие проекта предусматривает определение поддельных (созданных с помощью нейросетей) или отредактированных документов: фото, подписи, логотипы, печати и т.д. как часть разработки системы безопасности при проведении транзакций.

# Документация для создания файла .exe (Windows) и .app (MacOS) упаковки и развертывания приложения

#### 1. Сoздаем директорию для хранения модели, данных (background.jpg, logo.png, requirements.txt, .ico, .icns etc.), инструкций и исполняемых файлов, например app.py
#### 2. Устанавливаем pyinstaller в cmd с помощью команды pip install pyinstaller
#### 3. Создаем файлы инструкций: app.spec и setup.py для создания .exe при вызове pyinstaller app.spec в cmd из директории проекта
#### 4. Собираем зависимости в файл requirements.txt (команда !pip freeze > requirements.txt в ячейке Jupiter notebook). Файл сохраняется в директории проекта
#### 5. Скачиваем иконки для логотипов или приложения с сайта https://www.logoai.com например https://www.logoai.com/png/1360 (для нашего приложения)
#### 6. Конвертируем нашу иконку в формат .ico (Windows) онлайн https://convertico.com или в формат .icns (MacOs) онлайн https://cloudconvert.com/png-to-icns
#### 7. Скачиваем Inno Setup с ресурса https://jrsoftware.org/isinfo.php или сразу с https://jrsoftware.org/isdl.php
#### 8. Создаем установочный файл setup.iss который запускаем через приложение Inno Setup (этот файл должен быть в другой директории)

## Инструкции к исполняемому файлу app.py

#### В app.py важно указать правильный путь к директории модели model_path = resource_path("model/ai_imageclassifier.keras") или model_path = resource_path("ai_imageclassifier.keras") если модель находится в одной директории с остальными файлами. При создании .exe желательно все файлы разместить в одной директории чтобы избежать проблем при запуске приложения.
